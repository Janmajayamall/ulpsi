Task of private set intersection that returns the corresponding label instead of a boolean value indicating whether corresponding item is present or not reduces down to polynomial evaluation.

For example consider the set $x= [x_0, x_1, x_2, ..., x_n]$ and corresponding labels $y = [y_0, y_1, y_2, ..., y_n]$. Now let p(x) be polynomial such as
$$p(x_i) = y_i \space if \space x_i \in x, \space otherwise \space random $$
Now evaluating p(x) must either return correct label or some random data. The idea is to evaluate p(x) homomorphically with encrypted user input x.

However, we will run into issues with p(x) since it returns a random value if $x_i \nin x$. To avoid such cases we will require server to return a boolean value indicating whether requested value exists or not. Or we can assume the client has some way of detecting erronous values and can safely ignore such results. Throughout we will assume that we are in the latter case.

Now if server set has a million values then p(x) will have degree of a million. But this is problematic since evaluating such a polynomial homomorpihcally will require a very deep FHE circuit and will not result in an efficient construction.

One naive way to reduce polynomial degree is to divide the set into $k$ subsets and construct polynomial for each subset. Then evaluate user's input on each polynomial and return all results to the client. This increases response size by factor of $k$. As you will learn below that this helps, but we cannot rely on this alone since it can blow up the response size.

Cuckoo Hashing

Cuckoo hashing is a technique used to reduce hash collisions for storing data with hash as index while ensuring faster reads. The idea is to use $n$ tables and assign each table a different hash function. To insert, first try inserting the data in the first table. If there's a collision, then kick the existing value out and try inserting the existing value in the next table. If there's a collision again, then insert existing value and take whatever was at the place and try inserting the value in the next table. This process continues till all tables are exhausted. It is assured that if hash functions corresponding to each table are chosen correctly, then the probability of not being able to find a spot for a value in all tables is very less. In practice, n=3 suffices.

Recall that the biggest issue with p(x) is that its degree is of size of the set. Cuckoo hashing helps with reduce the size of set for a given value by making indices deterministic. The idea is that client uses cuckoo hashing to insert its values in 3 different hash tables. The server also uses the hash functions to create 3 different sets with the caveat that server hashes all its values using all hash functions and inserts them in all 3 sets. This assures that irrespective of in which hash table generated by client a value lands, it is always present in the corresponding set on the server. This increases the server data set by factor 3 but reduces the set of values with which a given user input could match (since the indices are now deterministic). In practice the reduces the polynomial degree drastically.

Once we apply cuccko hashing to entire dataset we can view each set as an individual database and client's hash tables are processed on the corresponding set.

Single hashed set

Since all elements are inserted at index = hash(data) and collisions are simply appended at the same row, hashed set may look like:

$$
\begin{array}{ccc}
a_{0,0} & a_{0,1} & \cdots \\
a_{1,0} & a_{1,1} & \cdots \\
\vdots \\
a_{500,0} & a_{500,1} & \cdots \\
\vdots
\end{array}
$$

where $h1(.)$ for any $row_i$ are equal. There are as many rows as output space of h1().

In practice a single hash table does not fit in a single ciphertext, thus we need to split as hash set and the corresponding request ciphertext into multiple sets. For example, if a single ciphertext can fit in only $k$ rows of hash table then we must split the hash set vertically into sets of $k$ rows. For ex, the set above transforms to

$$
\begin{array}{}
a_{0,0} & a_{0,1} & \cdots \\
a_{1,0} & a_{1,1} & \cdots \\
\vdots\\
a_{k-1,0} & a_{k-1,1} & \cdots \\
- & - & - \\
a_{k,0} & a_{k,1} & \cdots \\
a_{k+1,0} & a_{k+1,1} & \cdots \\
\vdots \\
a_{2k-1,0} & a_{2k-1,1} & \cdots \\
- & - & - \\
\vdots \\
\end{array}
$$

Let's zoom into a single InnerBox:

$$
\begin{array}{}
a_{0,0} & a_{0,1} & \cdots & a_{0,n-1} \\
a_{1,0} & a_{1,1} & \cdots & a_{1,n-1}\\
\vdots \\
a_{k-1,0} & a_{k-1,1} & \cdots & a_{k-1,n-1}\\
\end{array}
$$

As hinted before, to reduce the polynomial degree per row we can divide $n$ columns into multiple sets as per convenience. For example, let's say we want to limit the polynomial degree to $d$ then we can divide the column into $s = n/d$ sets and interpolate per row polynomial for each set separately. This increases response size by factor of $s$.

---

Cuckoo Hashing

Given 3 hash functions h1, h2, h3 we hash each item with each of the hash functions and create 3 different databases. This increases the storage on server by a factor of 3, but reduces request computation and communication cost eneromously.

The reason for the reduction is that instead of having to match every single item in client's set with every single item in server's set, we reduce it to a lot less by mapping each item to determinic indices within the hash table. However this increases the chances of collision and this is exactly where cuckoo hashing comes handy. If there is collision then kick the current value out, insert the new and hash and insert the old value using the next hash function in sequence. Since server hashes all values by all 3 hash functions and insert in all 3 dbs the value is guaranteed to exist at the expected index.

---

Polynomial interpolation

Think of DB with rows equal to hash table size. Server adds a new item to mapped rows. If there exists an item at the row and server adds to the next column.

For polynomial interpolation the columns for each row are divided in sets of max degree and interpolated separately.

## Newton's interpolation method

Consider the data points $x = [x_0, x_1, x_2, ..., x_{n-1}]$ and $y = [y_0, y_1, y_2, ..., y_{n-1}]$ . Using newton's interpolation we can interpolate a polynomial that evaluates to $y_i$ as $p(x_i)$.

$$p(x) = a_0 + a_1(x-x_0) + ... + a_{n-1}(x-x_{n-2})(x-x_{n-3})...(x-x_0)$$
Notice that $a_0 = y_0$

To figure out $a_i$ we must notice the following pattern:

$$f(x_1) = a_0 + a_1(x - x_0)$$
Since $f(x_1) = y_1$
$$ a_1 = \frac{y_1 - y_0}{(x_1 - x_0)}$$
Moreover since $f(x_2) = y_2$
$$ a_2 = \frac{\frac{y_2 - y_1}{(x_2 - x_1)} - \frac{y_1 - y_0}{(x_1 - x_0)}}{x_2 - x_0}$$
Notice that $a_2$ depends on $a_1$. And the pattern continues.

Now if we set $[y_{i}, y_{i-1}] = \frac{y_{i} - y_{i-1}}{x_{i} - x_{i-1}}$, then we can rewrite a_2 as
$$ a_2 = \frac{[y_2, y_1] - [y_1, y_0]}{x_2 - x_0}$$

We call this notation _divided differences_. We can further improve upon the notation as:
$$[y_k, y_{k-1}, ..., y_0] = \frac{[y_k,...,y_1] - [y_{k-1},...,y0]}{x_k - x_0}$$
Thus we can denote $a_2$ as $[y_2, y_1, y_0]$.

### Divided differences matrix

Notice that divided differences (ie $a_i$ values) depend on pervious values. Thus we can construct the following matrix to calculate $a_i$'s. I will illustrate the matrix using 5 data points.

$$
\begin{matrix}
a_0 & a_1 & a_2 & a_3 & a_4 \\
y_0 & [y_1, y_0] & [y_2, y_1, y_0] & [y_3, y_2, y_1, y_0] & [y_4, y_3, y_2, y_1, y_0]\\
y_1 & [y_2, y_1] & [y_3, y_2, y_1] & [y_4, y_3, y_2, y_1] & 0\\
y_2 & [y_3, y_2] & [y_4, y_3, y_2] & 0 & 0\\
y_3 & [y_4, y_3] & 0 & 0 & 0\\
y_4 & 0 & 0 & 0 & 0\\
\end{matrix}
$$

Notice that values in $col_{i+1}$ are calculated using values in $col_{i}$. For example,
$$a_4 = [y_4, y_3, y_2, y_1, y_0] = \frac{[y_4, y_3, y_2, y_1] - [y_3, y_2, y_1, y_0]}{x_4 - x_0}$$

## Horner'r rule to get coefficients

Using newton's interpolation we get p(x) of form:
$$p(x) = a_0 + a_1(x-x_0) + ... + a_{n-1}(x-x_{n-2})(x-x_{n-3})...(x-x_0)$$

But for efficient homomorphic polynomial evaluation we will require $p(x)$ in form
$$p(x) = \sum_{i=0}^{n-1} c_i x^i$$

We apply Horner's rule to get values for $c_i$'s. We start with constant polynomial with value of $a_{n-1} = [y_{n-1}, ..., y_0]$, multiply it with polynomial $(x - x_{n-1})$, and add the next value of $a_i$ in sequence, that is $a_{n-2}$. We repeat the procedure till $a_0$. For intuition we are constructing $p(x)$ as
$$p(x) = (((a_{n-1}(x-x_{n-2})) + a_{n-2})(x-x_{n-3}) + a_{n-3})...+a_{n-0}$$

```
/// p_x is viewed through its coefficients in ascending order of degree
let p_x = 0
for i in n-1..1 {
	p_x += a_{i}
	p_x *= (x - x_{i-1})
}
p_x += a_0
```

# Implementation

The entire dataset is processed using three hash functions to create 3 BigBoxes. Each ItemLabel is present in all three boxes at a given index of the hash table. 

## BigBox

BigBox is the hash table that stores data. It has as many rows as hash table size. Each new item label that lands on the same row is appended after that last item inserted (ie in next free column). 

To ease runtime processing, BigBox is further divided into 2D InnerBoxes. A row in BigBox corresponds to a InnerBoxRow of InnerBox. This implies that viewing BigBox as 2d array of InnerBoxes, there are as many as `Hash table size / No. of InnerBoxRows in InnerBox` rows of InnerBoxes. Let's call each row of InnerBox a segment. Each segment can contain many InnerBoxes and this cannot be determined at start, since arbitrarily no. of values may be inserted in each row. 

To insert an ItemLabel at a row, first map it to a segment, that is an InnerBoxRow. Then find the first InnerBox in the segment with free space at the mapped InnerBoxRow and proceed to insert the ItemLabel at InnerBoxRow in the found InnerBox. If none of the InnerBoxes in the segment has free columns, the create a new one, append it to the segment and insert the ItemLabel. 

Note that the insertion procedure implies that each segment might have different no. of InnerBoxes. 

## InnerBox

InnerBox has CtSlots/PsiPtSlots InnerBoxRows. A single InnerBoxRows spans across multiple real rows since a single ItemLabel value is stored across multiple rows (PsiPtSlots to be exact). More concretely, InnerBox contains 3 (one for item, one for label, and one for coefficients) u32 2D array of of dimension `CtSlots x EvalDegree`. 

The rationale for structuring inner box as such is that it eases polynomial interpolation and convert each column into BFV Plaintexts. At runtime, for homomorphic polynomial interpolation on encrypted query, each column in InnerBox can be easily converted to BfvPlaintexts for homomorphic polynomial interpolation.

There's a subtle issue with the way we handle inserts above. Since each real row is used for polynomial interpolation, what if there exists two same values in different columns in item's 2d array. This implies we expect the polynomial to ouput two different values on the same input. This isn't possible. To avoid this issue, instead of just finding the first InnerBox that has space for ItemLabel we should also assure that none of the chunks of item collide with existing chunks in their respective real rows. 


